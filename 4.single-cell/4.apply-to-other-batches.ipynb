{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and apply models to single cell profiles from other data batches\n",
    "\n",
    "We will apply classifiers to these data to prioritize samples that we predict to have specific drug-tolerance mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import joblib\n",
    "import pathlib\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from pycytominer.cyto_utils import infer_cp_features\n",
    "\n",
    "from utils.ml_utils import model_apply\n",
    "from utils.single_cell_utils import process_sites, normalize_sc\n",
    "\n",
    "sys.path.append(\"../0.generate-profiles\")\n",
    "from scripts.profile_util import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "batch = \"2019_11_20_Batch6\"\n",
    "plate = 217762\n",
    "\n",
    "feature_filter = [\"Object\", \"Location\", \"Count\", \"Parent\"]\n",
    "scaler_method = \"standard\"\n",
    "seed = 123\n",
    "n_randomly_sampled_cell_frac_per_site = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load locations of single cell files\n",
    "config = pathlib.Path(\"../0.generate-profiles/profile_config.yaml\")\n",
    "pipeline, single_cell_files = load_config(config, append_sql_prefix=False, local=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "model_file = pathlib.Path(\"models\", \"multiclass_cloneAE_wildtype.joblib\")\n",
    "top_model = joblib.load(model_file)\n",
    "\n",
    "shuffle_model_file = pathlib.Path(\"models\", \"multiclass_cloneAE_wildtype_shuffled.joblib\")\n",
    "top_shuffle_model = joblib.load(shuffle_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metadata_plate_map_name</th>\n",
       "      <th>Metadata_well_position</th>\n",
       "      <th>Metadata_clone_number</th>\n",
       "      <th>Metadata_plate_ID</th>\n",
       "      <th>Metadata_plate_filename</th>\n",
       "      <th>Metadata_treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217762</td>\n",
       "      <td>B02</td>\n",
       "      <td>BZ017</td>\n",
       "      <td>217762</td>\n",
       "      <td>20191120-20191115-LoDensity</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217762</td>\n",
       "      <td>B03</td>\n",
       "      <td>WT002</td>\n",
       "      <td>217762</td>\n",
       "      <td>20191120-20191115-LoDensity</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217762</td>\n",
       "      <td>B04</td>\n",
       "      <td>WT008</td>\n",
       "      <td>217762</td>\n",
       "      <td>20191120-20191115-LoDensity</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217762</td>\n",
       "      <td>B05</td>\n",
       "      <td>WT009</td>\n",
       "      <td>217762</td>\n",
       "      <td>20191120-20191115-LoDensity</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217762</td>\n",
       "      <td>B06</td>\n",
       "      <td>BZ018</td>\n",
       "      <td>217762</td>\n",
       "      <td>20191120-20191115-LoDensity</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Metadata_plate_map_name Metadata_well_position Metadata_clone_number  \\\n",
       "0                   217762                    B02                 BZ017   \n",
       "1                   217762                    B03                 WT002   \n",
       "2                   217762                    B04                 WT008   \n",
       "3                   217762                    B05                 WT009   \n",
       "4                   217762                    B06                 BZ018   \n",
       "\n",
       "   Metadata_plate_ID      Metadata_plate_filename Metadata_treatment  \n",
       "0             217762  20191120-20191115-LoDensity               DMSO  \n",
       "1             217762  20191120-20191115-LoDensity               DMSO  \n",
       "2             217762  20191120-20191115-LoDensity               DMSO  \n",
       "3             217762  20191120-20191115-LoDensity               DMSO  \n",
       "4             217762  20191120-20191115-LoDensity               DMSO  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load platemap and metadata\n",
    "workspace_dir = pipeline[\"workspace_dir\"]\n",
    "batch_dir = pathlib.Path(workspace_dir, \"backend\", batch)\n",
    "metadata_dir = pathlib.Path(\"../0.generate-profiles\", \"metadata\", batch)\n",
    "\n",
    "barcode_plate_map_file = pathlib.Path(metadata_dir, \"barcode_platemap.csv\")\n",
    "barcode_plate_map_df = pd.read_csv(barcode_plate_map_file)\n",
    "\n",
    "plate_map_name = (\n",
    "    barcode_plate_map_df\n",
    "    .query(\"Assay_Plate_Barcode == @plate\")\n",
    "    .Plate_Map_Name\n",
    "    .values[0]\n",
    ")\n",
    "\n",
    "plate_map_file = pathlib.Path(metadata_dir, \"platemap\", f\"{plate_map_name}.txt\")\n",
    "plate_map_df = pd.read_csv(plate_map_file, sep=\"\\t\")\n",
    "plate_map_df.columns = [x if x.startswith(\"Metadata_\") else f\"Metadata_{x}\" for x in plate_map_df.columns]\n",
    "plate_map_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load single cell data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_column = pipeline[\"aggregate\"][\"plate_column\"]\n",
    "well_column = pipeline[\"aggregate\"][\"well_column\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection to sqlite file\n",
    "single_cell_sqlite = single_cell_files[batch][\"plates\"][str(plate)]\n",
    "conn = sqlite3.connect(single_cell_sqlite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cols = f\"TableNumber, ImageNumber, {plate_column}, {well_column}\"\n",
    "image_query = f\"select {image_cols} from image\"\n",
    "image_df = (\n",
    "    pd.read_sql_query(image_query, conn)\n",
    "    .merge(\n",
    "        plate_map_df,\n",
    "        left_on=well_column,\n",
    "        right_on=\"Metadata_well_position\"\n",
    "    )\n",
    "    .drop([\"Metadata_well_position\"], axis=\"columns\")\n",
    ")\n",
    "\n",
    "print(image_df.shape)\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that image number is unique\n",
    "assert len(image_df.ImageNumber.unique()) == image_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sc_df = process_sites(\n",
    "    connection=conn,\n",
    "    imagenumbers=image_df.ImageNumber.tolist(),\n",
    "    image_df=image_df,\n",
    "    feature_filter=feature_filter,\n",
    "    seed=seed,\n",
    "    scaler_method=scaler_method,\n",
    "    random_sample=n_randomly_sampled_cell_frac_per_site,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sc_df.shape)\n",
    "sc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set data and reindex to match feature list\n",
    "test_file = pathlib.Path(\"data\", \"single_cell_test.tsv.gz\")\n",
    "test_df = pd.read_csv(test_file, sep=\"\\t\")\n",
    "\n",
    "cp_feature_order = infer_cp_features(test_df)\n",
    "\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_file = pathlib.Path(\"coefficients/single_cell_multiclass_coefficients.tsv\")\n",
    "coef_df = pd.read_csv(coef_file, sep=\"\\t\")\n",
    "\n",
    "print(coef_df.shape)\n",
    "coef_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert the feature order and the model are equivalent\n",
    "assert cp_feature_order == coef_df.feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex features in the proper order before saving\n",
    "meta_features = infer_cp_features(sc_df, metadata=True)\n",
    "reindex_features = meta_features + cp_feature_order\n",
    "sc_reindexed_df = sc_df.reindex(reindex_features, axis=\"columns\")\n",
    "\n",
    "print(sc_reindexed_df.shape)\n",
    "sc_reindexed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output file\n",
    "sc_output_file = pathlib.Path(f\"data/single_cell_{batch}_plate_{plate}_random_cells.tsv.gz\")\n",
    "sc_reindexed_df.to_csv(sc_output_file, sep=\"\\t\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_recode = {\"WT parental\": 0, \"Clone A\": 1, \"Clone E\": 2}\n",
    "y_recode_reverse = {y: x for x, y in y_recode.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_df = sc_reindexed_df.reindex(cp_feature_order, axis=\"columns\")\n",
    "meta_df = sc_reindexed_df.reindex(meta_features, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_scores_df = model_apply(\n",
    "    model=top_model,\n",
    "    x_df=sc_df.fillna(0),\n",
    "    meta_df=meta_df,\n",
    "    y_recode=y_recode_reverse,\n",
    "    data_fit=\"other_batch\",\n",
    "    shuffled=False,\n",
    "    predict_proba=True\n",
    ")\n",
    "\n",
    "output_file = pathlib.Path(f\"scores/{batch}_{plate}_real_model_othersinglecells.tsv.gz\")\n",
    "real_scores_df.to_csv(output_file, sep=\"\\t\", compression=\"gzip\", index=False)\n",
    "\n",
    "print(real_scores_df.shape)\n",
    "real_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_scores_df = model_apply(\n",
    "    model=top_shuffle_model,\n",
    "    x_df=sc_df.fillna(0),\n",
    "    meta_df=meta_df,\n",
    "    y_recode=y_recode_reverse,\n",
    "    data_fit=\"other_batch\",\n",
    "    shuffled=True,\n",
    "    predict_proba=True\n",
    ")\n",
    "\n",
    "output_file = pathlib.Path(f\"scores/{batch}_{plate}_shuffled_model_othersinglecells.tsv.gz\")\n",
    "shuffled_scores_df.to_csv(output_file, sep=\"\\t\", compression=\"gzip\", index=False)\n",
    "\n",
    "print(shuffled_scores_df.shape)\n",
    "shuffled_scores_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
